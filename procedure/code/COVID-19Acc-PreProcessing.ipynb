{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: RP- Spatial Accessibility of COVID-19 Healthcare Resources in Illinois Pre-Processing Script\n",
    "---\n",
    "\n",
    "This is a script that automates the data gathering and pre-processing for our reproduction of Kang et al.\n",
    "\n",
    "**Reproduction of**: Rapidly measuring spatial accessibility of COVID-19 healthcare resources: a case study of Illinois, USA\n",
    "\n",
    "Original study *by* Kang, J. Y., A. Michels, F. Lyu, Shaohua Wang, N. Agbodo, V. L. Freeman, and Shaowen Wang. 2020. Rapidly measuring spatial accessibility of COVID-19 healthcare resources: a case study of Illinois, USA. International Journal of Health Geographics 19 (1):1â€“17. DOI:[10.1186/s12942-020-00229-x](https://ij-healthgeographics.biomedcentral.com/articles/10.1186/s12942-020-00229-x).\n",
    "\n",
    "Reproduction Authors: Joe Holler, Kufre Udoh, Derrick Burt, Drew An-Pham, & Spring '21 Middlebury Geog 0323.\n",
    "\n",
    "Reproduction Materials Available at: [RP-Kang Repository](https://github.com/derrickburt/RP-Kang-Improvements)\n",
    "\n",
    "Created: `29 Jun 2021`\n",
    "Revised: `29 Jun 2021`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules\n",
    "Import necessary libraries to run this model.\n",
    "See `requirements.txt` for the library versions used for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import folium, itertools, os, time, warnings\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Directories\n",
    "\n",
    "Because we have restructured the repository for replication, we need to check our working directory and make necessary adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use to set work directory properly\n",
    "if os.getcwd() == '/home/jovyan/work/RP-Kang2020/procedure/code':\n",
    "    os.chdir('../../')\n",
    "if os.getcwd() == '/home/jovyan/work/RP-Kang2020/':\n",
    "    None \n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Plot the Street Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not os.path.exists(\"data/raw/private/Chicago_Network_Buffer.graphml\"):\n",
    "    G = ox.graph_from_place('Chicago', network_type='drive', buffer_dist = 24140.2) # pulling the drive network the first time will take a while\n",
    "    ox.save_graphml(G, 'raw/private/Chicago_Network_Buffer.graphml')\n",
    "else:\n",
    "    G = ox.load_graphml('raw/private/Chicago_Network_Buffer.graphml', node_type=str)\n",
    "ox.plot_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get unique counts for each road network\n",
    "# turn nodes and edges in geodataframes\n",
    "nodes, edges = ox.graph_to_gdfs(G, nodes=True, edges=True)\n",
    "\n",
    "# count\n",
    "print(edges['maxspeed'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate/Pre-Process Census Data  with API\n",
    "\n",
    "*Note* you will need to download a new module called 'censusdata'\n",
    "\n",
    "To do this, open a terminal in the cybergisx environment and type:\n",
    "\n",
    "```pip install censusdata```\n",
    "\n",
    "**Note: we deviate from the original paper's methodology here bringing in a larger buffer distance of census tracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load module\n",
    "import censusdata as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "# Read in all Illinois tracts using census API\n",
    "pop_api = cd.download('acs5', 2018,\n",
    "                             cd.censusgeo([('state', '17'), ('tract', '*')]),\n",
    "                             ['B01001_001E', 'B01001_016E', 'B01001_017E', 'B01001_018E', 'B01001_019E', \n",
    "                              'B01001_020E', 'B01001_021E', 'B01001_022E', 'B01001_023E', 'B01001_024E', \n",
    "                              'B01001_025E', 'B01001_040E', 'B01001_041E', 'B01001_042E', 'B01001_043E', \n",
    "                              'B01001_044E', 'B01001_045E', 'B01001_046E', 'B01001_047E', 'B01001_048E',\n",
    "                              'B01001_049E'])\n",
    "\n",
    "# check\n",
    "#pop_api.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reformat and Rename columns\n",
    "# Sum + Rename 50+ population\n",
    "pop_api['OverFifty'] = pop_api.iloc[:, 1:21].sum(axis=1)\n",
    "\n",
    "# Rename Total \n",
    "pop_api['TotalPop'] = pop_api['B01001_001E']\n",
    "\n",
    "# Drop irrelevant columns\n",
    "pop_api = pop_api.drop(pop_api.columns[0:21], axis=1)\n",
    "\n",
    "# Check\n",
    "pop_api.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD CODE TO SAFE INTO RAW DATA FOLDER\n",
    "# Create column from index tract # -- we will need thee tract ID for a join\n",
    "pop_api['TRACTCE'] = pop_api.index\n",
    "\n",
    "# Convert to string \n",
    "pop_api['TRACTCE'] = pop_api['TRACTCE'].astype(str)\n",
    "\n",
    "# Slice last 6 digits (tract id)\n",
    "pop_api['TRACTCE'] = pop_api['TRACTCE'].str.slice(-6)\n",
    "\n",
    "# Check\n",
    "pop_api.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note: We are using a larger subset of data here\n",
    "len(pop_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zip Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all Illinois tracts using census API\n",
    "zip_api = cd.download('acs5', 2019,\n",
    "                             cd.censusgeo([('state', '17'), ('zip code tabulation area', '*')]),\n",
    "                             ['B01003_001E'])\n",
    "\n",
    "# check\n",
    "zip_api.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename population column\n",
    "pop_col = {\"B01003_001E\":\"pop\"}\n",
    "zip_api = zip_api.rename(columns=pop_col)\n",
    "\n",
    "# Create column from index tract # -- we will need thee tract ID for a join\n",
    "zip_api['ZCTA5CE10'] = zip_api.index\n",
    "\n",
    "# Convert to string \n",
    "zip_api['ZCTA5CE10'] = zip_api['ZCTA5CE10'].astype(str)\n",
    "\n",
    "# Slice last 6 digits (tract id)\n",
    "zip_api['ZCTA5CE10'] = zip_api['ZCTA5CE10'].str.slice(6,11)\n",
    "\n",
    "# Check\n",
    "zip_api.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zip_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate/Pre-Process COVID-19 with Requests\n",
    "\n",
    "Download covid data that will be kjoined to zip code geographies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import geojson\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately... I have not found how to access archived COVID-119 case data, so this data is cases from 4/6/2020 - 6/30/2021 \n",
    "# set file path\n",
    "fp_covid = 'https://idph.illinois.gov/DPHPublicInformation/api/COVIDExport/GetZip'\n",
    "\n",
    "# make reqeuest\n",
    "r_covid = requests.get(fp_covid)\n",
    "\n",
    "# save request as dataframe\n",
    "covid_cases = pd.DataFrame.from_dict(json.loads(r_covid.content))\n",
    "\n",
    "# check\n",
    "covid_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change confirmed cases to cases\n",
    "cases_col = {'zip':\"ZCTA5CE10\", \"confirmed_cases\":\"cases\"}\n",
    "covid_cases = covid_cases.rename(columns=cases_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge covid case data with zip code geographis to normalize cases\n",
    "covid_api = covid_cases.merge(zip_api, how=\"inner\", on=\"ZCTA5CE10\")\n",
    "covid_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate/Pre-Process Census Boundary Shapefiles with FTP Site\n",
    "\n",
    "#### Note: Here, we extract *census tracts* and *zip code geographies* based on their spatial relationship (intersection) with the street network\n",
    "\n",
    "Census TIGER/Line shapefiles can bee accessed from ftp://ftp2.census.gov/geo/tiger/ using !wget\n",
    "\n",
    "File path for Cook County 2010 tracts: ftp://ftp2.census.gov/geo/tiger//TIGER2010/TRACT/2010/tl_2010_17031_tract10.zip\n",
    "\n",
    "File path for Illinois 2010 tracts: ftp://ftp2.census.gov/geo/tiger//TIGER2018/TRACT/tl_2018_17_tract.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check directory -- we want to downlaod the raw data directly into our pre-processing data folder\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download census tract shapefiles to data/raw/public/Pre-Processing/ for All of Chicago (017)\n",
    "if not os.path.exists('data/raw/public/Pre-Processing/tl_2018_24_tract.zip'):\n",
    "    !wget -P data/raw/public/Pre-Processing/ ftp://ftp2.census.gov/geo/tiger//TIGER2018/TRACT/tl_2018_24_tract.zip\n",
    "    # Extract shapefiles\n",
    "    !unzip -d data/raw/public/Pre-Processing/ data/raw/public/Pre-Processing/tl_2018_24_tract.zip\n",
    "    # read in all census tracts for Illinois\n",
    "    tracts_shp = gpd.read_file('data/raw/public/Pre-Processing/tl_2018_24_tract.shp')\n",
    "else:\n",
    "    # read in all census tracts for Illinois\n",
    "    tracts_shp = gpd.read_file('data/raw/public/Pre-Processing/tl_2018_24_tract.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set crs to WGS 84\n",
    "tracts_shp = tracts_shp.to_crs(epsg=4326)\n",
    "\n",
    "# check crs\n",
    "print(tracts_shp.crs)\n",
    "\n",
    "# check length\n",
    "print(len(tracts_shp))\n",
    "\n",
    "# check column names\n",
    "tracts_shp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns for join\n",
    "new_names = {\"GEOID10\":\"GEOID\", \"TRACTCE10\":\"TRACTCE\"}\n",
    "tracts_shp = tracts_shp.rename(columns=new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Tracts shape with Tracts Population data\n",
    "## This drops duplicate values so that we do not end up with\n",
    "overfifty_data = tracts_shp.merge(pop_api.drop_duplicates(subset=['TRACTCE']), how='left', on=\"TRACTCE\")\n",
    "len(overfifty_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check directory -- we want to downlaod the raw tract data directly into our data folder\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download zip code shapefiles to data/raw/public/Pre-Processing/ for entire US\n",
    "## I have not yet found a way to select by state before extracting\n",
    "if not os.path.exists('data/raw/public/Pre-Processing/cb_2018_us_zcta510_500k.zip'):\n",
    "    !wget -P data/raw/public/Pre-Processing/ ftp://ftp2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_zcta510_500k.zip\n",
    "    # Extract shapefiles\n",
    "    !unzip -d data/raw/public/Pre-Processing/ data/raw/public/Pre-Processing/cb_2018_us_zcta510_500k.zip\n",
    "    # read in zip code data\n",
    "    usa_zip = gpd.read_file('data/raw/public/Pre-Processing/cb_2018_us_zcta510_500k.shp')\n",
    "else:\n",
    "    # read in zip code data\n",
    "    usa_zip = gpd.read_file('data/raw/public/Pre-Processing/cb_2018_us_zcta510_500k.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only illinois zip code data\n",
    "## there may be some zip codes outside of Illinois included in this selecti\n",
    "## it's only meant to reduce the size, the proper data will be insured with\n",
    "## a join in the coming code cells\n",
    "ill_zip = usa_zip.loc[(usa_zip['GEOID10'] >= '60002') & (usa_zip['GEOID10'] <= '63433')]\n",
    "\n",
    "# set crs to WGS 84\n",
    "ill_zip = ill_zip.to_crs(epsg=4326)\n",
    "\n",
    "# check crs\n",
    "print(ill_zip.crs)\n",
    "\n",
    "# check length\n",
    "print(len(ill_zip))\n",
    "\n",
    "# renamw column names\n",
    "ill_zip.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Population and COVID Data to Zip and Tract Shapefiles and Save To Data Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join pop_api to censustracts\n",
    "pop_tracts_geo = tracts_shp.merge(pop_api, how='left', on='TRACTCE')\n",
    "# Drop extra columns\n",
    "pop_tracts_geo = pop_tracts_geo.drop(pop_tracts_geo.columns[5:10], axis=1)\n",
    "pop_tracts_geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join covid_zip to zip code geographis \n",
    "covid_zip_geo = ill_zip.merge(covid_api, how='left', on='ZCTA5CE10')\n",
    "# Drop extra columns\n",
    "# covid_zip_geo = covid_zip_geo.drop(covid_zip_geo.columns[5:10], axis=1)\n",
    "covid_zip_geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Population and Covid Data only where they intersect the street nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find zip covde polygons that contain a G node\n",
    "covid_selection = covid_zip_geo.contains(nodes)\n",
    "covid_selection.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find tract  polygons that contain a G node\n",
    "tract_selection = pop_tracts_geo.contains(nodes)\n",
    "covid_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hospital Data\n",
    "\n",
    "Note that 999 is treated as a \"NULL\"/\"NA\" so these hospitals are filtered out. This data contains the number of ICU beds and ventilators at each hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals = gpd.read_file('./data/raw/public/HospitalData/Chicago_Hospital_Info.shp')\n",
    "hospitals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate/Pre-Process Hospital with Requests -- Still Drafting this\n",
    "\n",
    "documentation for requests: https://docs.python-requests.org/en/master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD CODE TO SAFE INTO RAW DATA FOLDER\n",
    "# set file paths for general care and icu beds\n",
    "fp_gen = 'https://opendata.arcgis.com/datasets/6ac5e325468c4cb9b905f1728d6fbf0f_0.geojson'\n",
    "fp_icu = 'https://healthdata.gov/resource/uqq2-txqb.json'\n",
    "\n",
    "# requests for general care and icu beds\n",
    "r_gen = requests.get(fp_gen)\n",
    "r_icu = requests.get(fp_icu)\n",
    "\n",
    "# get hospitals \n",
    "hospitals_gen = gpd.GeoDataFrame.from_features(geojson.loads(r_gen.content),  crs=\"EPSG:26971\")\n",
    "hospitals_icu = pd.DataFrame.from_dict(json.loads(r_icu.content))\n",
    "\n",
    "# filter for icu and general care\n",
    "hospitals_gen = hospitals_gen.loc[(hospitals_gen['STATE'] == 'IL') & (hospitals_gen['TYPE'] == 'GENERAL ACUTE CARE')]\n",
    "# ERROR Here: it is only taking the first thousand\n",
    "hospitals_icu = hospitals_icu[['hospital_pk', 'collection_week', 'state', 'city', 'ccn', 'hospital_name', 'zip', 'ccn', 'address', 'total_icu_beds_7_day_avg']]\n",
    "\n",
    "# capitalize join column \n",
    "hospitals_icu.rename(columns={'address':'ADDRESS'}, inplace=True)\n",
    "\n",
    "# join\n",
    "hospitals_api = hospitals_gen.merge(hospitals_icu, on='ADDRESS')\n",
    "\n",
    "# check \n",
    "hospitals_icu['city'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
